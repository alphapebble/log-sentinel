{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b78bf9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# llm_vector_demo.ipynb\n",
    "{\n",
    " \"cells\": [\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# LLM Summarization & Embedding Demo (Ollama, Pinecone/Qdrant)\\n\",\n",
    "    \"This notebook demonstrates sessionization, LLM summarization, embedding generation, and pushing to a vector DB.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"import pandas as pd\\n\",\n",
    "    \"from analytics.sessionizer import sessionize_logs\\n\",\n",
    "    \"from llm.ollama_summarizer import summarize_session_ollama\\n\",\n",
    "    \"from vector_search.embedding_and_vector import get_embedding_ollama\\n\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 1. Load and Sessionize Logs\\n\",\n",
    "    \"Use a sample DataFrame (replace with real logs as needed).\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# Example synthetic log\\n\",\n",
    "    \"df = pd.DataFrame({\\n\",\n",
    "    \"    'timestamp': pd.date_range('2023-01-01', periods=25, freq='H'),\\n\",\n",
    "    \"    'user': ['user1']*10 + ['user2']*10 + ['user3']*5,\\n\",\n",
    "    \"    'event': ['login', 'file', 'logout', 'login', 'alert']*5\\n\",\n",
    "    \"})\\n\",\n",
    "    \"sessions = sessionize_logs(df, window_size=10)\\n\",\n",
    "    \"print(f'Number of sessions: {len(sessions)}')\\n\",\n",
    "    \"print('First session sample:', sessions[0][:2])\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 2. Summarize Sessions with Ollama LLM\\n\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"summaries = [summarize_session_ollama(session) for session in sessions]\\n\",\n",
    "    \"print('First summary:', summaries[0])\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 3. Generate Embeddings for Summaries\\n\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"embeddings = [get_embedding_ollama(summary) for summary in summaries]\\n\",\n",
    "    \"print('First embedding:', embeddings[0][:5])\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 4. (Optional) Push to Pinecone or Qdrant\\n\",\n",
    "    \"# from vector_search.embedding_and_vector import push_to_pinecone, push_to_qdrant\\n\",\n",
    "    \"# push_to_pinecone(session_id, embedding, metadata, index_name, api_key, env)\\n\",\n",
    "    \"# push_to_qdrant(session_id, embedding, metadata, collection_name, url)\\n\"\n",
    "   ]\n",
    "  }\n",
    " ],\n",
    " \"metadata\": {\n",
    "  \"kernelspec\": {\n",
    "   \"display_name\": \"Python 3\",\n",
    "   \"language\": \"python\",\n",
    "   \"name\": \"python3\"\n",
    "  },\n",
    "  \"language_info\": {\n",
    "   \"name\": \"python\",\n",
    "   \"version\": \"3.10\"\n",
    "  }\n",
    " },\n",
    " \"nbformat\": 4,\n",
    " \"nbformat_minor\": 2\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
